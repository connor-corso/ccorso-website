[
    {
        "id":"0",
        "title": "CGCPhotos",
        "sections": 
        [
            {
                "title": "Introduction",
                "text": "This is my biggest and most advanced project that I have worked on, I am starting to work on it as of October 10th. This project aims to be a custom build replacement for photoprism that has support for Google Motion Photos. To learn more about Google Motion Photos you'll have to check out my guide down below but in short they are little videos embedded into the same file asa picture that you take on a Google Pixel when you turn on \"Top Shot\". I have moved away from Google Photos for a few reasons and I have searched for a selfhosted alternative to use, I found and used photoprism for a while and I liked the person/animal classification AI sauce that it used however it lacked support for Motion Photos and so I thought that I would be able to build myself a fully featured alternative. This project description covers my work on this and will be updated as I work on this project"
            },
            {
                "title": "Step 1",
                "text": "Plan out the architecture of the project, for this I think that I will maybe draw some picturs of what will provide what, I plan to use a microservices approach I think is the correct term, where I will have multiple docker images running little parts of the whole thing that work together. I will have one container that runs the frontend, this will be on React with Material UI. The backend system that handles the pics will be running in Python with FastAPI, and it potentially will talk to another python process running FastAPI that is responsible for pulling out the motion photos and splitting it into the picture part and the video part. The splitter will be capable of using CPU transcoding since the videos are stored in .265 and I think that it makes the most sense to convert the videos when you pull them out of the pictures. I think that this makes sense because when clients go to look at them because most clients don't support .265 playback natively and waiting to transcode them until they are needed would result in a processing delay and additional programming work to figure out if a video has been transcoded and then if it hasn't, transcoding it then saving the transcoded video over the original so that I don't have to transcode it again."
            },
            {
                "title": "Step 2",
                "text": "Write out some skeleton code for the API, maybe get a basic implementation working with curl, test to see if I can get SQL up and going by copying what I did for my monitoring station which used a db and FastAPI"
            },
            {
                "title": "Step 3",
                "text": "Get an ugly but semi-functional frontend working to make testing the backend easier and so that I can get a feel for how I would like the good copy of the frontend to look like and what features it should have"
            },
            {
                "title": "Step 4",
                "text": "Fix all of the issues that the backend has, start to implement the motion photos splitting system, this could be implemented as a schedulable batch job"
            },
            {
                "title": "Step 5",
                "text": "Pretty up the frontend and see what needs to be done from here"
            }
            

        ]
    },
    {
        "id":"1",
        "title": "First STM32 Project",
        "sections":
        [
            {
                "title": "",
                "text": "Working with PWM and servo motors \nThis project has a servo motor connected to PB6, a switch connected to PA4 and a laser connected to pin PA2.\nThe device will read in the status of the pull up pin PA4 to see if the switch has been toggled, and then will start operation of the toy\nWhen the device is on, pin PA2 will be set and the laser turned on. Then the bigBounce method will be called, then the randomBounce method, and then the bigBounce method again before looping\nbigBounce takes no arguments and will first look at the value in the timer compare register to see where the servo is currently positioned, and then will start at the opposite end and slowly move across to the other side\nrandomBounce takes no arguments and will generate a random number between 0 and 14, and based on that number will call randomWobble with a different base position argument\nrandomWobble will take an base, an int and will then move in a quick back and forth motion around that base position"
            }
        ]
        
    },
    {
        "id":"3",
        "title": "Remodelling My Website",
        "sections": 
        [
            {
                "title": "Introduction",
                "text": "After graduating Trent with a CS degree I have been slowly poking away at my website trying to polish it up. Originally I had a little site written up in PHP with some basic CSS styling however I got bored pretty quickly and gave up. This write up talks about my experience redoing my website with React using Material UI to make it nice and pretty",
                "images":
                [
                    {
                        "imageLocation": "screenshot_old_puke_green_website.png",
                        "imageAlternateText": "picture of my old gross website",
                        "imageWidth": "30%"
                    }
                ]
            },
            {
                "title": "End Goal",
                "text": "I would like my website to have four pages, a home page, a projects page, a selfhosted services page, and a guide page for selfhosting services. The home page could have a preamble talking about me and then I would like to have it have a sample of each subpage displayed on it. I am going to start with the projects page as that is the page that I have the most content for and that I think will allow me to show what I have been working on. Then I will implement a home page that has the projects page displayed on it multiple times that will be slowly replaced when I finish the selfhosted services and guide pages complete."
            },
            {
                "title": "Implementation Details",
                "text": "Currently the projects page will get all of its data from a json file that contains an array of projects. Each project will have multiple sections in it that contain a section title, section text and then an  array of images that contains the image location as well as alternate text and image width properties. The website is in a GitHub repo and upon pushing changes GitHub Actions will automatically go out and build a container of the latest changes and push that container to Docker Hub. This updated container is picked up by Watchtower and the container is automatically updated on my server. This way all that I have to worry about is making the website and the deployment is taken care of automatically."
            },
            {
                "title": "Problems Discovered Along The Way",
                "text": "I wanted to keep my old website up while I worked on this new website, with the new website being accessible via www.ccorso.ca/projects and any other path going to the old website. This worked however the new website had nothing to serve at /projects and so it just returned an error. To get around this I made the website accessible at website.ccorso.ca and worked towards a proper solution using react-router-dom and setting a custom nginx.conf that had the line \"try_files $uri /index.html;\" in it that would default to /index.html whenever the path was not known to nginx."
            },
            {
                "title": "Key Lessons Learned",
                "text": "I don't have any key lessons learned as of yet because I'm still working on it in the early stages"

            }
        ]
    },
    {
        "id":"4",
        "title": "Working With Google Motion Photos",
        "sections": 
        [
            {
                "title": "Introduction",
                "text": "Google Camera (aka Gcam) has a toggle for \"Top Shot\" which allows you to take Motion Photos (MPs). Motion photos are pictures that also contain a short video from before you take the picture. Normally these videos are only accessible when you use Google Photos, however if Google has a way of extracting these images then there must be some way for other applications to access these videos. With this project I plan on first building a basic web app that takes a motion photo upload and splits it into both the regular image and the video."
            },
            {
                "title": "How To Extract the file offsets",
                "text": "I have been playing around with figuring out how to work with MPs ever since I ran out of free storage and started to migrate all of my data to a self hosted Google Photos alternative, photoprism. Once I realized that photoprism did not have support for MPs I tried looking around for another selfhosted solution that would support the feature. I could not find a solution so I decided to look into how to extract the videos myself and I first built a bash script as a proof of concept. The script can be found at the link below. It works by taking the name of the photo as an argument and it will then use grep to look at the text data within the picture and it extracts the second length field. This field tells you how long the image is in bytes, and is used with dd to extract all of the bytes after that length and store them in a .mp4 container.",
                "images":
                [
                    {
                        "imageLocation": "screenshot_of_gmp_sizes.png",
                        "imageAlternateText": "A screenshot showing the fields embedded within the google motion photo", 
                        "imageWidth": "30%"
                    }
                ],
                "links":
                [
                    {
                        "linkText": "link to basic shell script",
                        "link": "https://droppy.ccorso.ca/$/Yj2Yc"
                    }
                ]
            },
            {
                "title": "How To Do This In A Web App?",
                "text": "I plan on having a Python backend that uses fastAPI to expose a service that will take a motion photo and it will return the photo after the video has been removed, as well as the video itself.",
                "links":
                [
                    {
                        "linkText": "link to the backend github repo",
                        "link": "https://github.com/connor-corso/motion-photos-extraction-backend"
                    }
                ]
            }

        ]
    }
]
